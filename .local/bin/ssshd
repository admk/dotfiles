#!/usr/bin/env kxh_python
import re
import sys
import time
import shlex
import shutil
import socket
import getpass
import datetime
import argparse
import subprocess
import tempfile
from pathlib import Path


_logdir = '.sash_logs'
(Path.home() / _logdir).mkdir(exist_ok=True)

SLURM_SCRIPT = """#!/bin/bash
#SBATCH -p {args.partition}
#SBATCH -o {logdir}/%x_%j_%N.out
#SBATCH -e {logdir}/%x_%j_%N.err
#SBATCH -N {args.node_count}
#SBATCH --cpus-per-task={cpus}
#SBATCH --gres={gres}
{sbatch_extra}

cd $HOME

# find open port
PORT=$(python -c 'import socket; s=socket.socket(); s.bind(("", 0)); print(s.getsockname()[1]); s.close()')
scontrol update JobId="$SLURM_JOB_ID" Comment="$PORT"

echo "********************************************************************"
echo "Starting sshd on port $PORT"
echo "Script:" {script_name}
echo "Date:" $(date)
echo "Allocated node:" $(hostname)
echo "Path:" $(pwd)
echo "Listening on:" $PORT
echo "********************************************************************"

# additional commands
{acmd}

# sleep 1
# {queue_cmd}

# start sshd server on the available port
/usr/sbin/sshd -D -p $PORT -f /dev/null -h $HOME/.ssh/id_rsa
# sleep {time_in_seconds}
"""


def submit_slurm_job(args):
    print(f"date: {datetime.datetime.now():%Y-%m-%d %H:%M:%S}")
    autossh = shutil.which('autossh')
    if not autossh:
        print("autossh is not found, fallback to ssh.")
        autossh = 'ssh'
    else:
        autossh = f'{autossh} -M 0'
    sbatch_extra = ''
    if args.node:
        sbatch_extra += f"""#SBATCH -w {args.node}\n"""
    if args.time:
        sbatch_extra += f"""#SBATCH --time={args.time}\n"""
    try:
        gpus = int(args.gres.split(':')[-1])
        cpus = int(args.cpus_per_gpu) * gpus
    except ValueError:
        gpus = 0
        cpus = int(args.cpus_per_gpu)
    if args.queue_recursively:
        queue_cmd = ' '.join(sys.argv)
    else:
        queue_cmd = ''
    acmd = [shlex.quote(a) for a in args.additional_command]
    acmd = [re.sub(r"^'", r'"', a) for a in acmd]
    acmd = [re.sub(r"'$", r'"', a) for a in acmd]
    acmd = ' '.join(acmd)
    time_in_seconds = 604800  # 7 days
    temp_file = tempfile.NamedTemporaryFile(
        prefix='sash_', mode='w', delete=True)
    with temp_file as f:
        script = SLURM_SCRIPT.format(
            logdir=_logdir, autossh=autossh, args=args,
            gres=args.gres, cpus=cpus, sbatch_extra=sbatch_extra,
            queue_cmd=queue_cmd, acmd=acmd, time_in_seconds=time_in_seconds,
            script_name=f.name)
        print(f"args: {args!r}")
        print(f"autossh: {autossh!r}")
        f.write(script)
        f.flush()
        print(f"--- SLURM SCRIPT [{f.name}] ---")
        print(script)
        print("--- END SLURM SCRIPT ---")
        bargs = args.sbatch_args.strip().strip('"')
        bargs = shlex.split(args.sbatch_args)
        cmd = ['sbatch'] + list(bargs) + [f.name]
        print(f"command: {' '.join(cmd)}")
        output = subprocess.check_output(cmd, cwd=Path().home())
    jobid = output.decode().split()[-1]
    print(f"jobid: {jobid}")
    print ('Now waiting for the job to start...')
    time.sleep(1)
    cmd = ['squeue', '-h', '-j', jobid, '-o', '%T;%u;%R;%k']
    status, user, node, port = subprocess.check_output(cmd).decode().split(';')
    status = status.strip().lower()
    node = node.strip()
    print(f"status: {status}")
    if args.now and status != 'running':
        print(
            f'Job failed to start, reason {node}, cancelling job {jobid}...')
        subprocess.run(['scancel', jobid], check=True)
        return 1
    if status == 'running':
        print(f"user: {user}")
        print(f"node: {node}")
        print(f"port: {port}")
        print('You can now connect to the host with:')
        print(f"ssh {user}@{node} -p {port}")
    else:
        print('Job is not yet started.')
    return 0


def parse_args():
    parser = argparse.ArgumentParser(
        description='Submit a reverse SSH job to SLURM.')
    parser.add_argument(
        '-p', '--partition', type=str, default='gpu',
        help='Partition to submit to.')
    parser.add_argument(
        '-N', '--node-count', type=int, default=1, help='Number of nodes.')
    parser.add_argument(
        '-c', '--cpus-per-gpu', type=int, default=16, help='Number of CPU cores.')
    parser.add_argument(
        '-g', '--gres', type=str, default='gpu:a100-sxm4-80gb:1')
    parser.add_argument(
        '-w', '--node', type=str, default=None)
    parser.add_argument(
        '-t', '--time', type=str, default=None,
        help='Time limit for the job.')
    parser.add_argument(
        '-a', '--sbatch-args', type=str, default='',
        help='Additional arguments to pass to sbatch.')
    parser.add_argument(
        '-n', '--now', action='store_true',
        help='If set, the job will either start or fail immediately.')
    parser.add_argument(
        '-q', '--queue-recursively', action='store_true',
        help='Queue another job recursively.')
    argv = sys.argv[1:]
    try:
        split_pos = argv.index('--')
        argv, command = argv[:split_pos], argv[split_pos + 1:]
    except ValueError:
        command = []
    args = parser.parse_args(argv)
    args.additional_command = command
    return args


def main(args=None):
    sys.exit(submit_slurm_job(args or parse_args()))


if __name__ == '__main__':
    main()
