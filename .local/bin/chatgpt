#!/usr/bin/env python3
import re
import sys
from datetime import datetime

import pyperclip
from pygments import lexers, formatters, highlight
from termcolor import colored
from prompt_toolkit import prompt

import openai

openai.api_key = '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'


class Chat:
    role_map = {
        'user': colored('?', 'green'),
        'assistant': colored('>', 'yellow'),
        'system': colored('!', 'light_grey'),
        'error': colored('x', 'red'),
    }
    shortcuts = {
        'improve': [
            {'role': 'system', 'content': "As an academic writing improver for a machine learning paper, your task is to provide a corrected and improved version of the user's text. Your objective is to reorganize and rephrase the text using standard American English to make it clearer, more precise, academic, formal, and concise. You will only reply the improved paragraphs and nothing else, do not write explanations."},
        ],
        'improve_chinese': [
            {'role': 'system', 'content': "作为机器学习论文的学术写作改进AI工具，你的任务是为用户改善写作。通过重新组织和重新表达文章，使用规范语言，使其更清晰、更精确、更学术化、更正式和更简明。你只需要回复改进的段落，无需提供解释。"}
        ],
        'improve_rebuttal': [
            {'role': 'system', 'content': "As an academic writing improver for a machine learning paper rebuttal, your task is to provide a corrected and improved version of the user's rebuttal to a paper review. Your objective is to reorganize and rephrase the text using standard American English to make it clearer, more precise, academic, formal, and concise. Please write polite and persuasive rebuttals. You will only reply the improved paragraphs and nothing else, do not write explanations."},
        ],
        'sembr': [
            {'role': 'system', 'content':
r"""Your task is to perform semantic line breaks on the user's LaTeX source code input. Make sure to always break lines at the end of sentences and subsentences. This is typically after ',', ';', ':', '.', '?', but be mindful of acronyms. You may also opt to break the line before conjunctions (e.g., 'at', 'with', 'to', 'for', 'as', 'and') and verbs. Avoid creating line breaks within semantically related constructs. Keep each line to a maximum of 10 words. Please refrain from altering equations and algorithms within LaTeX environments. You will only reply the output and nothing else, do not write explanations.
Here is an example before semantic line breaks:
```latex
Inspired by this, we introduce \Method{}, which performs adversarial augmentations polices that preserves to the semantic information of the images rather than adding \( \ell_p \)-bounded adversarial noise.  Our objective is a bi-level optimization, where the inner level samples policies from a set of all possible augmentations \( \mathcal{A} \), in order to maximize the loss, and the outer level performs model training with adversarial polices:
\begin{equation}
    \arg\min_{\boldsymbol\theta} \mathbb{E}_{(\bx, y) \sim \mathcal{D}_{t}}\bracks*{\max_{\mathcal{T} \sim \mathcal{A}} \mathcal{L}\parens*{f_{\boldsymbol\theta}(\mathcal{T}\parens*{\bx_{i}^{\prime}}), y}}.\label{eq:method}
\end{equation}
Intuitively, \Method{} thus finds the most ``adversarial'' augmentation policies for the current images, and use that to train the model in order to prevent unlearnable ``shortcuts'' from emerging during model training.
```
And after semantic line breaks:
```latex
Inspired by this,
we introduce \Method{},
which performs adversarial augmentations polices
that preserves to the semantic information
of the images
rather than adding \( \ell_p \)-bounded adversarial noise.
Our objective
is a bi-level optimization,
where the inner level
samples policies
from a set of all possible augmentations \( \mathcal{A} \),
in order to maximize the loss,
and the outer level performs model training
with adversarial polices:
\begin{equation}
    \arg\min_{\boldsymbol\theta}
    \mathbb{E}_{
        (\bx, y) \sim \mathcal{D}_{t}
    }\bracks*{
        \max_{\mathcal{T} \sim \mathcal{A}}
        \mathcal{L}\parens*{
            f_{\boldsymbol\theta}(
                \mathcal{T}
                \parens*{\bx_{i}^{\prime}}
            ), y
        }
    }.
    \label{eq:method}
\end{equation}
Intuitively,
\Method{} thus finds the most ``adversarial''
augmentation policies
for the current images,
and use that to train the model
in order to prevent unlearnable ``shortcuts''
from emerging during model training.
```
"""},
        ],
    }

    def __init__(self):
        super().__init__()
        self.clear()
        self.lexer = lexers.get_lexer_by_name('markdown', stripall=True)
        self.formatter = formatters.TerminalFormatter()

    def highlight(self, text):
        return highlight(text, self.lexer, self.formatter)

    def clear(self):
        self.messages = []

    def save(self, file_name=None):
        if not file_name:
            file_name = f'chatgpt_{datetime.now():%Y-%m-%d %H:%M:%S}.txt'
        with open(file_name, 'w', encoding='utf-8') as file:
            for m in self.messages:
                file.write(f"{m['role']}: {m['content']}\n")
        return file_name

    def interactive_exit(self):
        save = None
        while save not in ['y', 'n', 'Y', 'N', '']:
            save = prompt('Save transcript (y/N): ')
        if save in ['y', 'Y']:
            file_name = self.save()
            print(f'Exit, transcript saved at {file_name!r}.')
        sys.exit(0)

    def request(self, question, print_out=True):
        match = re.match('/([a-zA-Z_]+)', question)
        messages = []
        if match:
            match = match.group(1)
            if match == 'exit':
                self.interactive_exit()
            if match == 'clear':
                self.clear()
                return
            if match == 'paste':
                question = pyperclip.paste()
            else:
                try:
                    shortcut = self.shortcuts[match]
                except KeyError:
                    mark = self.role_map['error']
                    print(f'{mark} System command "/{match}" does not exist.')
                    return messages
                messages += shortcut
                question = question.replace(f'/{match}', '').strip()
        if question:
            messages.append({'role': 'user', 'content': question})
        if not messages:
            return messages
        response = openai.ChatCompletion.create(
            model='gpt-3.5-turbo',
            messages=self.messages + messages)
        reply = response['choices'][0]['message']['content'].strip()
        messages.append({'role': 'assistant', 'content': reply})
        self.messages += messages
        if print_out:
            self.print(messages)
        return messages

    def print(self, messages):
        for m in messages:
            if m['role'] == 'user':
                continue
            mark = self.role_map[m["role"]]
            content = self.highlight(m["content"])
            print(f'{mark} {content}')


if __name__ == '__main__':
    chat = Chat()
    if len(sys.argv) > 1:
        question = ' '.join(sys.argv[1:])
        chat.request(question)
    else:
        while True:
            try:
                #  print(colored('? ', 'green'), end='')
                question = prompt('? ')
            except (KeyboardInterrupt, EOFError):
                chat.interactive_exit()
            chat.request(question)
